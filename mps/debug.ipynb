{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import umps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "def embedding_pixel(batch, label: int = 0):\n",
    "    pixel_size = batch.shape[-1] * batch.shape[-2]\n",
    "    x = batch.view(*batch.shape[:-2], pixel_size)\n",
    "    # x[:] = 0\n",
    "    x = torch.stack([x, 1-x], dim=-1)\n",
    "    # x = x / torch.sum(x, dim=-1).unsqueeze(-1)\n",
    "    x = x / torch.norm(x, dim=-1).unsqueeze(-1)\n",
    "    return x\n",
    "\n",
    "def embedding_label(labels: torch.Tensor):\n",
    "    emb = torch.zeros(labels.shape[0], 2)\n",
    "    emb[torch.arange(labels.shape[0]), labels] = 1\n",
    "    return emb\n",
    "\n",
    "def filiter_single_channel(batch):\n",
    "    return batch[0, ...]\n",
    "\n",
    "def filter_dataset(dataset, allowed_digits=[0, 1]):\n",
    "    indices = []\n",
    "    for i in range(len(dataset)):\n",
    "        _, label = dataset[i]\n",
    "        if label in allowed_digits:\n",
    "            indices.append(i)\n",
    "    return torch.utils.data.Subset(dataset, indices)\n",
    "\n",
    "img_size = 16\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(filiter_single_channel),\n",
    "    transforms.Lambda(embedding_pixel),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.QMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "trainset = filter_dataset(trainset, allowed_digits=[0, 1])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path is not set, setting...\n",
      "Found the path\n",
      "Initialized MPS unitaries\n"
     ]
    }
   ],
   "source": [
    "import unitary_optimizer\n",
    "umpsm = umps.uMPS(N = 16 * 16, chi = 2, d = 2, l = 2, layers = 1, device = \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(outputs, labels):\n",
    "    device = outputs.device\n",
    "    loss = torch.zeros(1, device=device, dtype=torch.float64)\n",
    "\n",
    "    for i in range(len(outputs)):\n",
    "        prob = outputs[i] if labels[i] == 0 else 1 - outputs[i]\n",
    "        loss -= torch.log(prob + 1e-8)\n",
    "    return loss\n",
    "\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    predictions = (outputs < 0.5).float()\n",
    "    correct = (predictions == labels).float().sum()\n",
    "    accuracy = correct / labels.numel()\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[43mumpsm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      2\u001b[0m u \u001b[38;5;241m@\u001b[39m u\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "u = umpsm.params[-1].grad.reshape(4, 4)\n",
    "u @ u.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_batch(outputs, target)\n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 11\u001b[0m \u001b[43mumpsm_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[1;32m     14\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m calculate_accuracy(outputs, target)\n",
      "File \u001b[0;32m~/Documents/presentation/QC_MPS/mps/unitary_optimizer.py:144\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m rg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;241m*\u001b[39m mhat \u001b[38;5;241m/\u001b[39m (torch\u001b[38;5;241m.\u001b[39msqrt(vhat) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Apply the exponential map to update the unitary\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m u_updated \u001b[38;5;241m=\u001b[39m \u001b[43mexp_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchi\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Update the unitary in the circuit\u001b[39;00m\n\u001b[1;32m    147\u001b[0m unitary\u001b[38;5;241m.\u001b[39mcopy_(u_updated\u001b[38;5;241m.\u001b[39mview(unitary\u001b[38;5;241m.\u001b[39mshape))\n",
      "File \u001b[0;32m~/Documents/presentation/QC_MPS/mps/unitary_optimizer.py:16\u001b[0m, in \u001b[0;36mexp_map\u001b[0;34m(u, rg)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexp_map\u001b[39m(u: torch\u001b[38;5;241m.\u001b[39mTensor, rg: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    Exponential map on the unitary manifold.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     res \u001b[38;5;241m=\u001b[39m  \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatrix_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mrg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m u\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closest_unitary(res)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "umpsm_op = unitary_optimizer.Adam(umpsm, lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    acc = 0\n",
    "    for data, target in trainloader:    \n",
    "        data = data.permute(1, 0, 2)\n",
    "        umpsm_op.zero_grad()\n",
    "        outputs = umpsm(data)\n",
    "        loss = loss_batch(outputs, target)\n",
    "        loss.backward()\n",
    "        umpsm_op.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = calculate_accuracy(outputs, target)\n",
    "        # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        acc += accuracy\n",
    "    acc /= len(trainloader)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    # print(\"grad\", umpsm.params[-1].grad)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.kraus_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00, -1.5151e-09,  3.6242e-10, -8.2355e-09],\n",
       "        [-1.5151e-09,  1.0000e+00,  3.9718e-09,  5.4807e-09],\n",
       "        [ 3.6242e-10,  3.9718e-09,  1.0000e+00,  7.3616e-09],\n",
       "        [-8.2355e-09,  5.4807e-09,  7.3616e-09,  1.0000e+00]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = torch.zeros(4, 4)\n",
    "\n",
    "for kraus_op in mps.kraus_ops[0]:\n",
    "    I += kraus_op.T @ kraus_op\n",
    "\n",
    "I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4929, 0.1871],\n",
       "        [0.1871, 0.5071]], dtype=torch.float64, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tpcp_mps\n",
    "from importlib import reload\n",
    "reload(tpcp_mps)\n",
    "\n",
    "mps = tpcp_mps.MPSTPCP(N=16 * 16, K=1, d=2)\n",
    "\n",
    "outputs = mps.forward(data[:, :, :].to(torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3217, 0.5300, 0.6689, 0.4137, 0.4518, 0.4848, 0.4619, 0.6848, 0.8434,\n",
       "        0.4206, 0.6056, 0.4578, 0.6694, 0.7811, 0.2808, 0.4834, 0.4791, 0.4612,\n",
       "        0.0448, 0.7090, 0.4482, 0.6645, 0.3723, 0.4935, 0.3612, 0.5337, 0.6680,\n",
       "        0.3314, 0.4152, 0.8303, 0.4398, 0.4487, 0.7049, 0.9043, 0.7533, 0.2612,\n",
       "        0.8024, 0.4165, 0.2396, 0.3580, 0.3231, 0.2031, 0.5297, 0.4053, 0.1495,\n",
       "        0.6114, 0.3828, 0.1742, 0.3090, 0.6286, 0.4317, 0.6117, 0.6485, 0.6831,\n",
       "        0.4552, 0.5844, 0.5443, 0.6155, 0.3997, 0.4054, 0.1457, 0.1112, 0.3017,\n",
       "        0.4169, 0.4252, 0.3610, 0.7113, 0.3329, 0.3020, 0.2280, 0.4437, 0.6049,\n",
       "        0.2926, 0.2494, 0.5580, 0.5982, 0.6938, 0.4332, 0.3964, 0.6479, 0.6917,\n",
       "        0.5261, 0.6665, 0.5378, 0.5206, 0.6813, 0.5700, 0.5287, 0.3308, 0.7020,\n",
       "        0.4728, 0.6162, 0.4287, 0.5274, 0.7051, 0.4734, 0.4715, 0.1893, 0.6181,\n",
       "        0.4499], dtype=torch.float64, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_gen = torch.randn(100, 16 * 16, 2)\n",
    "rand_gen /= torch.norm(rand_gen, dim=-1).unsqueeze(-1)\n",
    "\n",
    "mps.forward(rand_gen.to(torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4, 4])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  5.5511e-17, -5.5511e-17,  0.0000e+00],\n",
       "        [ 5.5511e-17,  1.0000e+00, -2.7756e-17,  2.7756e-17],\n",
       "        [-5.5511e-17, -2.7756e-17,  1.0000e+00,  5.5511e-17],\n",
       "        [ 0.0000e+00,  2.7756e-17,  5.5511e-17,  1.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = mps.kraus_ops[-1].grad[0]\n",
    "G = G / torch.norm(G)\n",
    "K = mps.kraus_ops[-1].detach()[0]\n",
    "\n",
    "\n",
    "A = torch.cat([G, K], dim=1)\n",
    "B = torch.cat([K, -G], dim=1)\n",
    "\n",
    "rg = A @ torch.linalg.inv(torch.eye(8) + 0.5 * 0.05 * B.T @ A) @ B.T @ K\n",
    "Kp = K - rg * 0.05\n",
    "\n",
    "Kp @ Kp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  1.9005],\n",
       "         [ 0.0000,  0.0000,  0.0000, -0.1128],\n",
       "         [ 0.0000,  0.0000,  0.0000, 21.8310],\n",
       "         [ 0.0000,  0.0000,  0.0000,  2.1302]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.kraus_ops[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[-0.0781, -0.2654,  0.9404, -0.1976],\n",
       "         [ 0.5015, -0.7846, -0.2378, -0.2761],\n",
       "         [-0.4079,  0.1087, -0.1895, -0.8865],\n",
       "         [-0.7589, -0.5496, -0.1522,  0.3143]]], dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00, -3.3307e-16, -2.6368e-16,  4.1633e-17],\n",
       "        [-3.3307e-16,  1.0000e+00,  2.2898e-16, -3.6082e-16],\n",
       "        [-2.6368e-16,  2.2898e-16,  1.0000e+00, -2.2204e-16],\n",
       "        [ 4.1633e-17, -3.6082e-16, -2.2204e-16,  1.0000e+00]],\n",
       "       dtype=torch.float64, grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.params[0][0] @ optimizer.params[0][0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[-0.0462, -0.5530, -0.5585, -0.6166],\n",
       "         [ 0.3898, -0.3660,  0.7532, -0.3832],\n",
       "         [ 0.6462, -0.4353, -0.2547,  0.5727],\n",
       "         [-0.6544, -0.6089,  0.2366,  0.3808]]], dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.kraus_ops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00, -1.6662e-16, -6.0210e-17, -4.3451e-17],\n",
       "        [-1.6662e-16,  1.0000e+00,  1.8244e-17, -6.5638e-17],\n",
       "        [-6.0210e-17,  1.8244e-17,  1.0000e+00,  1.2042e-16],\n",
       "        [-4.3451e-17, -6.5638e-17,  1.2042e-16,  1.0000e+00]],\n",
       "       dtype=torch.float64, grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = mps.kraus_ops[0].reshape(8, 4) \n",
    "\n",
    "K.T @ K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00, -9.8817e-19,  1.8542e-17,  1.5244e-16],\n",
       "        [-9.8817e-19,  1.0000e+00, -2.7013e-18, -3.7641e-17],\n",
       "        [ 1.8542e-17, -2.7013e-18,  1.0000e+00, -1.6334e-17],\n",
       "        [ 1.5244e-16, -3.7641e-17, -1.6334e-17,  1.0000e+00]],\n",
       "       dtype=torch.float64, grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.kraus_ops[0].T @ mps.kraus_ops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.33191124933472\n",
      "0.5390625\n",
      "88.33190862632068\n",
      "0.5390625\n",
      "88.33190369198766\n",
      "0.5390625\n",
      "88.33189689400702\n",
      "0.5390625\n",
      "88.3318887714528\n",
      "0.5390625\n",
      "88.33187990826016\n",
      "0.5390625\n",
      "88.331870888128\n",
      "0.5390625\n",
      "88.3318622538474\n",
      "0.5390625\n",
      "88.33185447344013\n",
      "0.5390625\n",
      "88.3318479147869\n",
      "0.5390625\n",
      "88.33184282967609\n",
      "0.5390625\n",
      "88.33183934745813\n",
      "0.5390625\n",
      "88.33183747780937\n",
      "0.5390625\n",
      "88.33183712152645\n",
      "0.5390625\n",
      "88.33183808782029\n",
      "0.5390625\n",
      "88.33184011627898\n",
      "0.5390625\n",
      "88.33184290152242\n",
      "0.5390625\n",
      "88.33184611857837\n",
      "0.5390625\n",
      "88.33184944715126\n",
      "0.5390625\n",
      "88.33185259321003\n",
      "0.5390625\n",
      "88.33185530665929\n",
      "0.5390625\n",
      "88.33185739425168\n",
      "0.5390625\n",
      "88.33185872730965\n",
      "0.5390625\n",
      "88.33185924422692\n",
      "0.5390625\n",
      "88.3318589480855\n",
      "0.5390625\n",
      "88.3318579000275\n",
      "0.5390625\n",
      "88.33185620925777\n",
      "0.5390625\n",
      "88.3318540206942\n",
      "0.5390625\n",
      "88.33185150135407\n",
      "0.5390625\n",
      "88.33184882654099\n",
      "0.5390625\n",
      "88.33184616680894\n",
      "0.5390625\n",
      "88.33184367653107\n",
      "0.5390625\n",
      "88.33184148470836\n",
      "0.5390625\n",
      "88.3318396884362\n",
      "0.5390625\n",
      "88.33183834922204\n",
      "0.5390625\n",
      "88.33183749213111\n",
      "0.5390625\n",
      "88.33183710754327\n",
      "0.5390625\n",
      "88.33183715514457\n",
      "0.5390625\n",
      "88.33183756965767\n",
      "0.5390625\n",
      "88.33183826774652\n",
      "0.5390625\n",
      "88.33183915550087\n",
      "0.5390625\n",
      "88.33184013592454\n",
      "0.5390625\n",
      "88.33184111591116\n",
      "0.5390625\n",
      "88.33184201227125\n",
      "0.5390625\n",
      "88.331842756487\n",
      "0.5390625\n",
      "88.3318432979895\n",
      "0.5390625\n",
      "88.33184360587457\n",
      "0.5390625\n",
      "88.33184366909131\n",
      "0.5390625\n",
      "88.33184349523891\n",
      "0.5390625\n",
      "88.3318431081909\n",
      "0.5390625\n",
      "88.33184254482423\n",
      "0.5390625\n",
      "88.33184185117\n",
      "0.5390625\n",
      "88.33184107830537\n",
      "0.5390625\n",
      "88.33184027829775\n",
      "0.5390625\n",
      "88.3318395004784\n",
      "0.5390625\n",
      "88.33183878826848\n",
      "0.5390625\n",
      "88.33183817672617\n",
      "0.5390625\n",
      "88.33183769091245\n",
      "0.5390625\n",
      "88.33183734511034\n",
      "0.5390625\n",
      "88.33183714286724\n",
      "0.5390625\n",
      "88.33183707777823\n",
      "0.5390625\n",
      "88.33183713488303\n",
      "0.5390625\n",
      "88.33183729252018\n",
      "0.5390625\n",
      "88.33183752446556\n",
      "0.5390625\n",
      "88.33183780217969\n",
      "0.5390625\n",
      "88.33183809699601\n",
      "0.5390625\n",
      "88.33183838210665\n",
      "0.5390625\n",
      "88.3318386342255\n",
      "0.5390625\n",
      "88.33183883484632\n",
      "0.5390625\n",
      "88.3318389710476\n",
      "0.5390625\n",
      "88.33183903583212\n",
      "0.5390625\n",
      "88.3318390280246\n",
      "0.5390625\n",
      "88.33183895177538\n",
      "0.5390625\n",
      "88.33183881574483\n",
      "0.5390625\n",
      "88.33183863205475\n",
      "0.5390625\n",
      "88.33183841510316\n",
      "0.5390625\n",
      "88.33183818033709\n",
      "0.5390625\n",
      "88.33183794307256\n",
      "0.5390625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[230], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m mps\u001b[38;5;241m.\u001b[39mforward(data[:, :, :]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat64))\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_batch(outputs, target)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import kraus_optimizer\n",
    "reload(kraus_optimizer)\n",
    "reload(tpcp_mps)\n",
    "# mps = tpcp_mps.MPSTPCP(N=16 * 16, K=2, d=2)\n",
    "# optimizer = kraus_optimizer.Adam(mps.kraus_ops, lr=0.0001)\n",
    "optimizer = kraus_optimizer.CayleySGDMomentum(mps.kraus_ops, lr=0.0001, beta=0.95, q=0.5, s=4)\n",
    "\n",
    "for _ in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = mps.forward(data[:, :, :].to(torch.float64))\n",
    "    loss = loss_batch(outputs, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())\n",
    "    print(calculate_accuracy(outputs, target))\n",
    "\n",
    "# for epoch in range(100):\n",
    "#     acc_tot = 0\n",
    "#     loss_tot = 0\n",
    "#     for data, target in trainloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = mps.forward(data[:, :, :].to(torch.float64))\n",
    "#         loss = loss_batch(outputs, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         acc = calculate_accuracy(outputs, target)\n",
    "#         acc_tot += acc\n",
    "#         loss_tot += loss.item()\n",
    "#     acc_tot /= len(trainloader)\n",
    "#     loss_tot /= len(trainloader)\n",
    "#     print(f\"Accuracy: {acc_tot:.4f}\")\n",
    "#     print(f\"Loss: {loss_tot:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0.0000, -20810.3705,      0.0000,  19047.8718],\n",
       "        [     0.0000,      0.0000,      0.0000,      0.0000],\n",
       "        [     0.0000, -25382.7747,      0.0000,   7647.4490],\n",
       "        [     0.0000,      0.0000,      0.0000,      0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.kraus_ops[-1].gra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5021\n",
      "Loss: 89.4934\n",
      "Accuracy: 0.5324\n",
      "Loss: 88.4154\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[257], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_batch(outputs, target)\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 17\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m acc \u001b[38;5;241m=\u001b[39m calculate_accuracy(outputs, target)\n\u001b[1;32m     20\u001b[0m acc_tot \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n",
      "File \u001b[0;32m~/Documents/presentation/QC_MPS/mps/kraus_optimizer.py:390\u001b[0m, in \u001b[0;36mCayleyAdam.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m G \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# 1 step of Cayley-Adam\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m X_new, M_new, v_new \u001b[38;5;241m=\u001b[39m \u001b[43mcayley_adam_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mM_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mG\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# In-place update\u001b[39;00m\n\u001b[1;32m    405\u001b[0m p\u001b[38;5;241m.\u001b[39mcopy_(X_new)\n",
      "File \u001b[0;32m~/Documents/presentation/QC_MPS/mps/kraus_optimizer.py:286\u001b[0m, in \u001b[0;36mcayley_adam_update\u001b[0;34m(X, M, v, G, beta1, beta2, l, q, s, step, eps)\u001b[0m\n\u001b[1;32m    280\u001b[0m M_new \u001b[38;5;241m=\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m M \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta1) \u001b[38;5;241m*\u001b[39m G\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# (5) v_{k+1} <- beta2 * v_k + (1 - beta2) * ||G(X_k)||^2\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m#     (Here, we store v as a scalar if following the paper.)\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m g_norm_sq \u001b[38;5;241m=\u001b[39m \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    287\u001b[0m v_new \u001b[38;5;241m=\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m v \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2) \u001b[38;5;241m*\u001b[39m g_norm_sq\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# (6) v_hat_{k+1} = v_{k+1} / (1 - beta2^{k+1})\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m# (7) r <- (1 - beta1^{k+1}) * sqrt(v_hat_{k+1}) + eps\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Note: in code, 'step' is the 1-based iteration index.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# So we use (step) in place of (k+1).\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/_tensor.py:765\u001b[0m, in \u001b[0;36mTensor.norm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    763\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mnorm, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim, dtype\u001b[38;5;241m=\u001b[39mdtype\n\u001b[1;32m    764\u001b[0m     )\n\u001b[0;32m--> 765\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/functional.py:1594\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnorm\u001b[39m(\u001b[38;5;28minput\u001b[39m, p: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m\"\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the matrix norm or vector norm of a given tensor.\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \n\u001b[1;32m   1503\u001b[0m \u001b[38;5;124;03m    .. warning::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;124;03m        (tensor(3.7417), tensor(11.2250))\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1594\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_torch_function_unary\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1595\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   1596\u001b[0m             norm, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim, out\u001b[38;5;241m=\u001b[39mout, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# NB. All the repeated code and weird python is to please TorchScript.\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m#     For a more compact implementation see the relevant function in `_refs/__init__.py`\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;66;03m# We don't do this for MPS or sparse tensors\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import kraus_optimizer\n",
    "\n",
    "reload(kraus_optimizer)\n",
    "\n",
    "# mps_tpcp = tpcp_mps.MPSTPCP(N=16 * 16, K=1, d=2)\n",
    "# optimizer = kraus_optimizer.CayleySGDMomentum(mps.kraus_ops, lr=0.005, beta=0.5, q=0.5, s=2)\n",
    "optimizer = kraus_optimizer.CayleyAdam(mps_tpcp.kraus_ops, lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    acc_tot = 0\n",
    "    loss_tot = 0\n",
    "    for data, target in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mps_tpcp.forward(data.to(torch.float64))\n",
    "        loss = loss_batch(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = calculate_accuracy(outputs, target)\n",
    "        acc_tot += acc\n",
    "        loss_tot += loss.item()\n",
    "        # print(loss.item())\n",
    "        # print(mps.kraus_ops[-1].sum())\n",
    "    acc_tot /= len(trainloader)\n",
    "    loss_tot /= len(trainloader)\n",
    "    print(f\"Accuracy: {acc_tot:.4f}\")\n",
    "    print(f\"Loss: {loss_tot:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, kraus_op in enumerate(mps_tpcp.kraus_ops):\n",
    "    kraus_op.data[:] = umpsm.params[i].reshape(4,4)\n",
    "    print(mps_tpcp.forward(data.to(torch.float64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.5022, -0.2951],\n",
       "          [ 0.5226,  0.6225]],\n",
       "\n",
       "         [[-0.5633, -0.2183],\n",
       "          [-0.4017,  0.6883]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4872, -0.5938],\n",
       "          [-0.6219, -0.1525]],\n",
       "\n",
       "         [[ 0.4394,  0.7160],\n",
       "          [-0.4228,  0.3399]]]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umpsm.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9207\n",
      "loss: 32.39418858531672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[254], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      9\u001b[0m umpsm_op\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mumpsm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_batch(outputs, target)\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/presentation/QC_MPS/mps/umps.py:246\u001b[0m, in \u001b[0;36muMPS.forward\u001b[0;34m(self, X, label)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     batch[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:, :, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_discriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/opt_einsum/contract.py:763\u001b[0m, in \u001b[0;36mContractExpression.__call__\u001b[0;34m(self, *arrays, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backends\u001b[38;5;241m.\u001b[39mhas_backend(backend) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays):\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contract_with_conversion(ops, out, backend, evaluate_constants\u001b[38;5;241m=\u001b[39mevaluate_constants)\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_contract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_constants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate_constants\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    766\u001b[0m     original_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(err\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39margs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/opt_einsum/contract.py:693\u001b[0m, in \u001b[0;36mContractExpression._contract\u001b[0;34m(self, arrays, out, backend, evaluate_constants)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The normal, core contraction.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    691\u001b[0m contraction_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_full_contraction_list \u001b[38;5;28;01mif\u001b[39;00m evaluate_constants \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontraction_list\n\u001b[0;32m--> 693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_core_contract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcontraction_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mevaluate_constants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate_constants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/opt_einsum/contract.py:591\u001b[0m, in \u001b[0;36m_core_contract\u001b[0;34m(operands, contraction_list, backend, evaluate_constants, **einsum_kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m         einsum_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m out_array\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;66;03m# Do the contraction\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m     new_view \u001b[38;5;241m=\u001b[39m \u001b[43m_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43meinsum_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtmp_operands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meinsum_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;66;03m# Append new items and dereference what we can\u001b[39;00m\n\u001b[1;32m    594\u001b[0m operands\u001b[38;5;241m.\u001b[39mappend(new_view)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/opt_einsum/sharing.py:151\u001b[0m, in \u001b[0;36meinsum_cache_wrap.<locals>.cached_einsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(einsum)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_einsum\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m currently_sharing():\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# hash modulo commutativity by computing a canonical ordering and names\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     backend \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/opt_einsum/contract.py:353\u001b[0m, in \u001b[0;36m_einsum\u001b[0;34m(*operands, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         einsum_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m->\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m parser\u001b[38;5;241m.\u001b[39mfind_output_str(einsum_str)\n\u001b[1;32m    351\u001b[0m     einsum_str \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mconvert_to_valid_einsum_chars(einsum_str)\n\u001b[0;32m--> 353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43meinsum_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/opt_einsum/backends/torch.py:45\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m     42\u001b[0m equation \u001b[38;5;241m=\u001b[39m convert_to_valid_einsum_chars(equation)\n\u001b[1;32m     44\u001b[0m torch, _ \u001b[38;5;241m=\u001b[39m _get_torch_and_device()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/functional.py:380\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    377\u001b[0m     _operands \u001b[38;5;241m=\u001b[39m operands[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# recurse incase operands contains value that has torch function\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# in the original implementation this line is omitted\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_operands\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39meinsum(equation, operands)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/torch/functional.py:338\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopt_einsum\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mopt_einsum\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# This wrapper exists to support variadic args.\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meinsum(): must specify the equation string and at least one operand, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mor at least one operand and its subscripts list\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    342\u001b[0m equation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# umpsm = umps.uMPS(N = 16 * 16, chi = 2, d = 2, l = 2, layers = 1, device = \"cpu\")\n",
    "umpsm_op = unitary_optimizer.Adam(umpsm, lr=0.01)\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    acc = 0\n",
    "    for data, target in trainloader:    \n",
    "        data = data.permute(1, 0, 2)\n",
    "        umpsm_op.zero_grad()\n",
    "        outputs = umpsm(data)\n",
    "        loss = loss_batch(outputs, target)\n",
    "        loss.backward()\n",
    "        loss_list.append(loss.item())\n",
    "        umpsm_op.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = calculate_accuracy(outputs, target)\n",
    "        # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        acc += accuracy\n",
    "    acc /= len(trainloader)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
